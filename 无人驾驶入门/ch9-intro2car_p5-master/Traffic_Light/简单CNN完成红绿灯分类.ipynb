{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简单CNN完成红绿灯分类\n",
    "- 参考 基于 Keras 的猫狗分类识别\n",
    "- tensorflow-gpu 1.13.1\n",
    "- keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPool2D,Activation,Dropout,Flatten,Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/steven/anaconda3/envs/tf13/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/steven/anaconda3/envs/tf13/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(32,32,3),filters=32,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(Conv2D(filters=32,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(Conv2D(filters=128,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "# 定义优化器\n",
    "adam = Adam(lr=1e-4)\n",
    "\n",
    "# 定义优化器，代价函数，训练过程中计算准确率\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range = 40,     # 随机旋转度数\n",
    "    width_shift_range = 0.2, # 随机水平平移\n",
    "    height_shift_range = 0.2,# 随机竖直平移\n",
    "    rescale = 1/255,         # 数据归一化\n",
    "    shear_range = 20,       # 随机错切变换\n",
    "    zoom_range = 0.2,        # 随机放大\n",
    "    horizontal_flip = True,  # 水平翻转\n",
    "    fill_mode = 'nearest',   # 填充方式\n",
    ") \n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1/255,         # 数据归一化\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1187 images belonging to 3 classes.\n",
      "Found 297 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# 生成训练数据\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'traffic_light_images/training',\n",
    "    target_size=(32,32),\n",
    "    batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "# 测试数据\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'traffic_light_images/test',\n",
    "    target_size=(32,32),\n",
    "    batch_size=batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'green': 0, 'red': 1, 'yellow': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 0.0146 - acc: 0.9958 - val_loss: 0.0036 - val_acc: 0.9966\n",
      "Epoch 2/5\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.0108 - acc: 0.9967 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.0160 - acc: 0.9967 - val_loss: 0.0039 - val_acc: 0.9966\n",
      "Epoch 4/5\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 0.0042 - acc: 0.9983 - val_loss: 9.5739e-04 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 0.0063 - acc: 0.9992 - val_loss: 9.3753e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa67c8538d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator,steps_per_epoch=len(train_generator),epochs=5,validation_data=test_generator,validation_steps=len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install h5py\n",
    "model.save('model_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=54x93 at 0x7FA67D229D68>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "label = np.array(['green','red', 'yellow'])\n",
    "# 载入模型\n",
    "model = load_model('model_cnn.h5')\n",
    "\n",
    "# 导入图片\n",
    "image = load_img('traffic_light_images/test/red/0ba83f83-a49c-4319-8ee2-547082ef7503.jpg')\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 32, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = image.resize((32,32))\n",
    "image = img_to_array(image)\n",
    "image = image/255\n",
    "image = np.expand_dims(image,0)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['red']\n"
     ]
    }
   ],
   "source": [
    "print(label[model.predict_classes(image)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of misclassified images =  0  out of 297\n",
      "accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "image_dir = \"traffic_light_images/test\"\n",
    "image_types = [\"red\", \"yellow\", \"green\"]\n",
    "total = 0\n",
    "miss = 0\n",
    "for im_type in image_types:\n",
    "    for file in glob.glob(os.path.join(image_dir, im_type, \"*\")):\n",
    "        total += 1\n",
    "        image = load_img(file)\n",
    "        image = image.resize((32,32))\n",
    "        image = img_to_array(image)\n",
    "        image = image/255\n",
    "        image = np.expand_dims(image,0)\n",
    "        predicted_label = label[model.predict_classes(image)]\n",
    "        if predicted_label[0] != im_type:\n",
    "            print(\"ture label: \",im_type, \"  predicted label: \", predicted_label[0])\n",
    "            miss += 1\n",
    "print(\"Number of misclassified images = \", miss,  ' out of '+ str(total))\n",
    "print(\"accuracy: \", 1-miss/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf13]",
   "language": "python",
   "name": "conda-env-tf13-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
